{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57226901",
   "metadata": {},
   "source": [
    "# Actuarial Standards of Practice (ASOP) Q&A Machine using Retrieval Augmented Generation (RAG)\n",
    "This project aims to create a Retrieval-Augmented Generation (RAG) process for actuaries to ask questions on a set of Actuarial Standards of Practice (ASOP) documents. The RAG process utilizes the power of the Large Language Model (LLM) to provide answers to questions on ASOPs.\n",
    "\n",
    "However, RAG is not without challenges, i.e., hallucination and inaccuracy. This code allows verifiability by providing the context it used to arrive at those answers. This process enables actuaries to validate the information provided by the LLM, empowering them to make informed decisions. By combining the capabilities of LLM with verifiability, this code offers actuaries a robust tool to leverage LLM technology effectively and extract maximum value.\n",
    "\n",
    "The current example uses either OpenAI's GPT 3.5 turbo AND a local LLM. Note that the current notebook is set up to output results from both models for comparison purposes.  \n",
    "Using a local LLM can address potential data privacy or security concerns.\n",
    "\n",
    "View license or further information about the local models used:\n",
    "- Solar 10.7B Instruct: [cc-by-nc-4.0](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0) (non-commercial use)\n",
    "- Mistral 7B Instruct: [Apache License 2.0](https://ollama.com/library/mistral/blobs/sha256:43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1)\n",
    "- [GPT4All embedding model](https://python.langchain.com/docs/integrations/text_embedding/gpt4all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c8d88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Initial Setup\n",
    "This setup includes loading environment variables from a `.env` file, setting the required environment variables, and importing the necessary modules for further processing. It ensures that the code has access to the required APIs and functions for the subsequent tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fc759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial set up\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the variables from .env file and set the API key (or user may manually set the API key)\n",
    "load_dotenv()  # This loads the variables from .env (not part of repo)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" # use when you want to debug or monitor the performance of your langchain applications\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv('LANGCHAIN_API_KEY') # use when accessing cloud-based language models or services that langchain integrates with\n",
    "\n",
    "# Import the necessary modules\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel # for RAG with source\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import glob\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35630ca8-a707-4445-b8a2-661fe3312d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "# use_OpenAI\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "db_directory = \"../data/chroma_db1\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", \n",
    "                 temperature=0) # context window size 16k for GPT 3.5 Turbo\n",
    "\n",
    "# Open source models used here are for illustration and educational purposes\n",
    "# Added _ALT at the end of variables to indicate alternative method as a comparison\n",
    "embeddings_model_ALT = GPT4AllEmbeddings()\n",
    "db_directory_ALT = \"../data/chroma_db2\"\n",
    "# define a local large language model for the augmented generation\n",
    "# Ollama is one way to easily run inference\n",
    "#llm = Ollama(model=\"solar:10.7b-instruct-v1-q5_K_M\")\n",
    "llm_ALT = Ollama(model=\"mistral:instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04673e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Load PDF Files and Convert to a Vector DB\n",
    "1. Create a function to load and extract text from PDF files in a specified folder. It defines a function called `load_pdfs_from_folder()` that takes a folder path as input and returns a list of extracted text documents from the PDF files in that folder.\n",
    "\n",
    "2. In the example, the folder path `../data/ASOP` is used, but you can modify it to point to your desired folder.\n",
    "\n",
    "3. By calling the `load_pdfs_from_folder()` function with the folder path, the code loads the PDF files, extracts the text using the PyPDFLoader, and stores the extracted text documents in the `docs` list.\n",
    "\n",
    "4. After loading and extracting the text, a `RecursiveCharacterTextSplitter` object is created with specific parameters for chunking the documents. The `split_documents()` method is then used to split the documents into smaller chunks based on the specified parameters.\n",
    "\n",
    "5. Finally, a Chroma vectorstore is created from the document splits. The vectorstore uses the defined embedding model for embedding the chunks and is saved to the predefined directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3b91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only when the DB directory is empty\n",
    "if not os.path.exists(db_directory) or not os.listdir(db_directory):\n",
    "    # Define a function to load and extract text from PDFs in a folder\n",
    "    def load_pdfs_from_folder(folder_path):\n",
    "        # Get a list of PDF files in the specified folder\n",
    "        pdf_files = glob.glob(f\"{folder_path}/*.pdf\")\n",
    "        docs = []\n",
    "        for pdf_file in pdf_files:\n",
    "            # Load the PDF file using the PyPDFLoader\n",
    "            loader = PyPDFLoader(pdf_file) \n",
    "            # Extract the text from the PDF and add it to the docs list\n",
    "            docs.extend(loader.load())\n",
    "        return docs\n",
    "    \n",
    "    # Example folder path\n",
    "    folder_path = '../data/ASOP'\n",
    "    \n",
    "    # Call the function to load and extract text from PDFs in the specified folder\n",
    "    docs = load_pdfs_from_folder(folder_path)\n",
    "    \n",
    "    # Create a text splitter object with specified parameters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200,\n",
    "        length_function=len,)\n",
    "    \n",
    "    # Split the documents into chunks using the text splitter\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    # Create a Chroma vector database from the document splits, using OpenAIEmbeddings for embedding\n",
    "    vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                        embedding=embeddings_model, \n",
    "                                        persist_directory=db_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46105ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Retrieve from the Vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9abd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Chroma vector database with specified parameters\n",
    "vectorstore = Chroma(embedding_function=embeddings_model, \n",
    "                     persist_directory=db_directory)\n",
    "\n",
    "## Alternative method using local open-source LLM\n",
    "vectorstore_ALT = Chroma(embedding_function=embeddings_model_ALT, \n",
    "                     persist_directory=db_directory_ALT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9744b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve and RAG chain\n",
    "\n",
    "# Create a retriever using the vector database as the search source\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", \n",
    "                                     search_kwargs={'k': 6, 'lambda_mult': 0.4})\n",
    "\n",
    "## Alternative method using local open-source LLM\n",
    "retriever_ALT = vectorstore_ALT.as_retriever(search_type=\"mmr\", \n",
    "                                     search_kwargs={'k': 6, 'lambda_mult': 0.4})\n",
    "\n",
    "# Use MMR (Maximum Marginal Relevance) to find a set of documents that are both similar to the input query and diverse among themselves\n",
    "# Increase the number of documents to get, and increase diversity (lambda mult 0.5 being default, 0 being the most diverse, 1 being the least)\n",
    "\n",
    "# Load the RAG (Retrieval-Augmented Generation) prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define a function to format the documents with their sources and pages\n",
    "def format_docs_with_sources(docs):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    sources_pages = \"\\n\".join(f\"{doc.metadata['source']} (Page {doc.metadata['page'] + 1})\" for doc in docs)\n",
    "    # Added 1 to the page number assuming 'page' starts at 0 and we want to present it in a user-friendly way\n",
    "\n",
    "    return f\"Documents:\\n{formatted_docs}\\n\\nSources and Pages:\\n{sources_pages}\"\n",
    "\n",
    "# Create a RAG chain using the formatted documents as the context\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs_with_sources(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create a parallel chain for retrieving and generating answers\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "## Alternative method using local open-source LLM\n",
    "# Create a RAG chain using the formatted documents as the context\n",
    "rag_chain_from_docs_ALT = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs_with_sources(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm_ALT\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create a parallel chain for retrieving and generating answers\n",
    "rag_chain_with_source_ALT = RunnableParallel(\n",
    "    {\"context\": retriever_ALT, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs_ALT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243e34a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Generate Q&A Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ceedb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output():\n",
    "    # Prompt the user for a question on ASOP\n",
    "    usr_input = input(\"What is your question on ASOP?: \")\n",
    "\n",
    "    # Invoke the RAG chain with the user input as the question\n",
    "    output = rag_chain_with_source.invoke(usr_input)\n",
    "    output_ALT = rag_chain_with_source_ALT.invoke(usr_input)\n",
    "\n",
    "    # Generate the Markdown output with the question, answer, and context\n",
    "    markdown_output = \"### Question\\n{}\\n\\n### Open AI Answer\\n{}\\n\\n\".format(output['question'], output['answer'])\n",
    "    markdown_output += \"### Local LLM Answer\\n{}\\n\\n### Open AI Context\\n\".format(output_ALT['answer'])\n",
    "\n",
    "    last_page_content = None  # Variable to store the last page content\n",
    "    i = 1 # Source indicator\n",
    "\n",
    "    # Iterate over the context documents to format and include them in the output\n",
    "    for doc in output['context']:\n",
    "        current_page_content = doc.page_content.replace('\\n', '  \\n')  # Get the current page content\n",
    "        \n",
    "        # Check if the current content is different from the last one\n",
    "        if current_page_content != last_page_content:\n",
    "            markdown_output += \"- **Open AI Source {}**: {}, page {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], doc.metadata['page'], current_page_content)\n",
    "            i = i + 1\n",
    "        last_page_content = current_page_content  # Update the last page content\n",
    "\n",
    "    markdown_output += \"\\n\\n### Local LLM Context\\n\"\n",
    "\n",
    "    last_page_content = None  # Variable to store the last page content\n",
    "    i = 1 # Source indicator\n",
    "\n",
    "    # Iterate over the context documents to format and include them in the output\n",
    "    for doc in output_ALT['context']:\n",
    "        current_page_content = doc.page_content.replace('\\n', '  \\n')  # Get the current page content\n",
    "        \n",
    "        # Check if the current content is different from the last one\n",
    "        if current_page_content != last_page_content:\n",
    "            markdown_output += \"- **Local LLM Source {}**: {}, page {}:\\n\\n{}\\n\".format(i, doc.metadata['source'], doc.metadata['page'], current_page_content)\n",
    "            i = i + 1\n",
    "        last_page_content = current_page_content  # Update the last page content\n",
    "\n",
    "    \n",
    "    # Display the Markdown output\n",
    "    display(Markdown(markdown_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54daa6",
   "metadata": {},
   "source": [
    "# Example questions related to ASOPs\n",
    "- explain ASOP No. 14\n",
    "- What are the considerations in choosing what methods to use for asset adequacy testing?\n",
    "- How are expenses reflected in cash flow testing based on ASOP No. 22?\n",
    "- What is catastrophe risk?\n",
    "- When do I update assumptions?\n",
    "- What should I do when I do not have credible data to develop non-economic assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36183436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is your question on ASOP?:  How do I consider what methods to use for asset adequacy testing?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Question\n",
       "How do I consider what methods to use for asset adequacy testing?\n",
       "\n",
       "### Open AI Answer\n",
       "When considering methods for asset adequacy testing, it is important to use appropriate analysis methods and professional judgment to determine the reasonableness of results. Techniques like cash flow testing and loss-ratio methods may be suitable depending on the nature of the asset, policy, and liability cash flows. The actuary should also consider quantifying the impacts of changes and select appropriate assumptions for the analysis.\n",
       "\n",
       "### Local LLM Answer\n",
       " To consider methods for asset adequacy testing, refer to the acceptable testing methods mentioned in the context. These include a gross premium reserve test and analyzing assets, their appropriateness for the analysis method, and the information and analysis used to support the determination that the method is appropriate. Use professional judgment when choosing a testing method and determining which assumptions should be varied. (Refer to sections 3.1 and 3.3.2 in your document.)\n",
       "\n",
       "### Open AI Context\n",
       "- **Open AI Source 1**: ../data/ASOP/asop022_167.pdf, page 13:\n",
       "\n",
       "3.4 Forming an Opinion with Respect to Asset Adequacy Analysis  \n",
       "⎯The actuary should use   \n",
       "appropriate analysis methods when forming an  opinion with respect to asset adequacy. In   \n",
       "judging whether the results from the asset adequacy analysis are satisfactory, the actuary should use professional judgment in determ ining which of the following, or other,   \n",
       "considerations apply:   \n",
       "   \n",
       "3.4.1 Reasonableness of Results  \n",
       "⎯The actuary should review the modeled future economic   \n",
       "and experience conditions and test results for reasonableness.\n",
       "- **Open AI Source 2**: ../data/ASOP/asop052_189.pdf, page 30:\n",
       "\n",
       "ASOP No. 52—September 2017    \n",
       "    \n",
       "25  (collected under the general heading of “asset ad equacy analysis”) in testing for adequacy of   \n",
       "reserves in light of th e assets supporting them. Foremost among these techniques was cash flow   \n",
       "testing. Asset adequacy analysis was designed as  an aggregate test to determine whether the   \n",
       "insurer should establish reserves in excess of the statutory minimums and includes methods of   \n",
       "quantifying this amount. To a degree, these same t echniques are paralleled in the determination   \n",
       "of certain components of a principle-based valuation.   \n",
       " Product design features introduced since the 1980s have led to a need for additional guidance   \n",
       "on how to reserve for products. Model Regulation 830, Valuation of Life Insurance Policies   \n",
       "Model Regulation (XXX), and Actuarial Guideline 38 (AG 38),  Application of the Valuation of   \n",
       "Life Insurance Policies Model Regulation (AXXX) , were developed to address concerns for\n",
       "- **Open AI Source 3**: ../data/ASOP/asop022_203.pdf, page 22:\n",
       "\n",
       "The reviewers believe the guidance is appropriate and therefore made no change in response to   \n",
       "this comment.     \n",
       "Comment    \n",
       "   \n",
       "   \n",
       "Response  One commentator suggested clarifying that asset adequacy reserves established in prior years   \n",
       "should be excluded when performing asset adequacy analysis.    \n",
       "   \n",
       "The reviewers believe the guidance is appropriate and therefore made no change in response to   \n",
       "this comment.     \n",
       "Comment    \n",
       "   \n",
       "   \n",
       "Response  One commentator suggested modifying the language to remove the implication that asset   \n",
       "adequacy analysis is a guarantee.    \n",
       "   \n",
       "The reviewers agree and modified the language.    \n",
       "Section 3.1 .1, Analysis Methods    \n",
       "Comment    \n",
       "   \n",
       "   \n",
       "Response  One commentator proposed additional disclosure when liability cash flows have a material   \n",
       "dependency on the asset cash flows and cash flow testing is not used.    \n",
       "   \n",
       "The reviewers believe the guidance covers these issues at the appropriate level of detail and made   \n",
       "no change in response to this comment.    \n",
       "Comment\n",
       "- **Open AI Source 4**: ../data/ASOP/asop022_203.pdf, page 13:\n",
       "\n",
       "should consider quantifying the impacts of these changes.       \n",
       "   \n",
       "The use of new methods, models, or assumptions for new liability  segments (for   \n",
       "example, a new line of business or product) or new asset  amounts is not a change   \n",
       "within the meaning of this section.   \n",
       "   \n",
       "3.1.11 Completeness When performing t he asset  adequacy analysis , the actuary  should   \n",
       "take into account anticipated material cash flows  such as renewal premiums,   \n",
       "guaranteed and nonguarant eed benefits  and charges , expenses, and taxes. In   \n",
       "determining the asset s supporting the tested  reserves and other liabilities , the   \n",
       "actuary should take into account any asset  segmentation system used by the   \n",
       "company.\n",
       "- **Open AI Source 5**: ../data/ASOP/asop022_167.pdf, page 12:\n",
       "\n",
       "small number of large individual claims over a short-term period.   \n",
       "   \n",
       "e. Loss-ratio methods may be appropria te when the asset, policy, and other   \n",
       "liability cash flows are of short dura tion. Under this method, moderately   \n",
       "adverse deviations in the actuarial assumptions underlying the morbidity or mortality costs may be tested. Loss-ra tio methods are described in ASOP    \n",
       "No. 5, Incurred Health and Disability Claims .   \n",
       "   \n",
       " If the actuary is uncertain as to whet her moderately adverse deviations in the   \n",
       "investment rate-of-return assumptions will have a material impact on the asset adequacy analysis results, then the actua ry should also test moderately adverse   \n",
       "deviations in the investment rate-of-return risk assumptions.   The actuary should document the asset adequacy analysis methods chosen.    \n",
       "   \n",
       "3.3.3 Assumptions  \n",
       "⎯In addition to selecting an appropriate analysis method, the actuary   \n",
       "should select appropriate assumptions. Accepted methods include the following:\n",
       "- **Open AI Source 6**: ../data/ASOP/asop044_160.pdf, page 14:\n",
       "\n",
       "ASOP No. 44—September 2009    \n",
       "   \n",
       "   \n",
       "7   \n",
       "  selected for a particular purpose, at each subsequent measurement date, the actuary   \n",
       "should consider whether the selected asset va luation method continue s to be appropriate   \n",
       "for that purpose. The actuary is not requir ed to do a complete reassessment at each   \n",
       "measurement date. However, if a significant ch ange in the principal’s objectives has been   \n",
       "communicated to the actuary (see secti on 3.2.2), the actuary should review the   \n",
       "appropriateness of the asset valuation method. Furthermore, if the asset valuation method   \n",
       "is other than market value, the actuary s hould review the appropriateness of the asset   \n",
       "valuation method if an event such as the following has occurred:   a. a significant change in the plan provis ions affecting cash flow (such as adding a   \n",
       "lump sum payment option, or freezing or te rminating the plan), in the actuarial   \n",
       "cost method or funding policy, or in participant demographics;\n",
       "\n",
       "\n",
       "### Local LLM Context\n",
       "- **Local LLM Source 1**: ../data/ASOP/asop022_167.pdf, page 11:\n",
       "\n",
       "assets, policies, or other liabilities may var y, or where the present value of combined   \n",
       "asset, liability, or other cash flows may vary  under different economic or interest-rate   \n",
       "scenarios.    \n",
       "  Asset adequacy analysis test methods  other than cash flow testing may be   \n",
       "appropriate in other situations. The follo wing are examples of acceptable methods.   \n",
       "These methods would test moderately adverse deviations in the actuarial   \n",
       "assumptions, except for the investment ra te-of-return assumptions. The actuary   \n",
       "should use professional judgment in choosing an appropriate testing method and in determining which assumptions should be varied for the particular test.   \n",
       "   \n",
       "a. A gross premium reserve test may be  appropriate where the policy and other   \n",
       "liability cash flows are sensitive to mode rately adverse deviations in the   \n",
       "actuarial assumptions underlying these cash flows. For example, this type of   \n",
       "method may be appropriate for term insurance backed by noncallable bonds,\n",
       "- **Local LLM Source 2**: ../data/ASOP/asop022_203.pdf, page 15:\n",
       "\n",
       "analysis  (see section 3.1 );   \n",
       "   \n",
       "c. the assets chosen, the methodology used for their selection, and their   \n",
       "appropriateness for the analysis method (see section 3.1);    \n",
       "   \n",
       "d. the asset adequacy analysis  methods chosen, and the information and analysis   \n",
       "used to support the determination that the method is appropriate for the reserves   \n",
       "and other liabilities  being tested (see section 3.1.1) ;\n",
       "- **Local LLM Source 3**: ../data/ASOP/asop032_196.pdf, page 22:\n",
       "\n",
       "Current Practices      \n",
       "    \n",
       "Tests of Financial Adequacy     \n",
       "    \n",
       "Several well -established formal methods are currently being used to test the financial adequacy of   \n",
       "Social Insurance Programs, as well as measures developed to assess the actuarial status and   \n",
       "sustainability of these Programs over different time periods.    \n",
       "    \n",
       "The frequency with which Programs assess their financial status varies. Some (OASDI, Medicare,   \n",
       "and PBGC, for instance) evaluate their financial position each year, while others, such as the   \n",
       "Railroad Retirement Board, may perform a valuation every third yea r.\n",
       "- **Local LLM Source 4**: ../data/ASOP/asop022_203.pdf, page 1:\n",
       "\n",
       "3.1.3 Reinsurance Ceded  5   \n",
       "3.1.4 Aggregation During Testing 5   \n",
       "3.1.5 Use of Cash Flows from Other Financial Calculations  5   \n",
       "3.1.6 Separate Account Assets  6   \n",
       "3.1.7 Management Action  6   \n",
       "3.1.8 Use of Data or Analyses Predating the Valuation Date  7   \n",
       "3.1.9 Testing Horizon  7   \n",
       "3.1.10 Changes in Methods, Models, or Assumptions  7   \n",
       "3.1.11 Completeness  7   \n",
       "3.1.12 Reliance on Others for Data, Projections, and Supporting Analysis  8   \n",
       "3.1.13 Subsequent Events  8   \n",
       "3.2 Forming an Opinion with Respect to Asset Adequacy Analysis  8   \n",
       "3.2.1 Reasonableness of Results  8   \n",
       "3.2.2 Adequacy of Reserves and Other Liabilities  8\n",
       "- **Local LLM Source 5**: ../data/ASOP/asop022_167.pdf, page 1:\n",
       "\n",
       "Section 3.  Analysis of Issues and Recommended Practices 4   \n",
       "3.1 Requirements to Consider 4 3.2 Appointed or Qualified Actuary 4 3.3 Statement of Opinion 4   \n",
       "3.3.1 Asset Adequacy Analysis 4 3.3.2 Analysis Methods 5 3.3.3 Assumptions 6 3.3.4 Additional Considerations 7   \n",
       "3.4 Forming an Opinion with Respect to Asset Adequacy Analysis 7   \n",
       "3.4.1 Reasonableness of Results 7\n",
       "- **Local LLM Source 6**: ../data/ASOP/asop007_128.pdf, page 2:\n",
       "\n",
       "3.2.1 Reasons for Cash Flow Testing 4 3.2.2 Cash Flow Testing is Not Always Necessary 4 3.2.3 Use of Analyses or Data Predating the Analysis Date 5   \n",
       "3.3 Identification of Assets 5   \n",
       "3.3.1 Choice of Asset Subsets to Use 5 3.3.2 Notional Asset Portfolios 5 3.3.3 Other Assets 5   \n",
       "3.4 Projection of Asset Cash Flows 5   \n",
       "3.4.1 Asset Characteristics 6 3.4.2 Investment Strategy 6\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5938771",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "- https://www.actuarialstandardsboard.org/standards-of-practice/\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/quickstart\n",
    "- https://python.langchain.com/docs/use_cases/question_answering/sources\n",
    "- https://python.langchain.com/docs/integrations/text_embedding/\n",
    "- https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All\n",
    "- https://chat.langchain.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
